{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9015ea-f557-467c-b97a-a024d2f9a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I grew up (b. 1965) watching and loving the Th...      0\n",
      "1  When I put this movie in my DVD player, and sa...      0\n",
      "2  Why do people who do not know what a particula...      0\n",
      "3  Even though I have great interest in Biblical ...      0\n",
      "4  Im a die hard Dads Army fan and nothing will e...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs after extraction\n",
    "train_df = pd.read_csv(r\"D:\\Machine Learning\\Recurrent Neural Network\\data\\archive\\train.csv\")\n",
    "valid_df = pd.read_csv(r\"D:\\Machine Learning\\Recurrent Neural Network\\data\\archive\\valid.csv\")\n",
    "test_df  = pd.read_csv(r\"D:\\Machine Learning\\Recurrent Neural Network\\data\\archive\\test.csv\")\n",
    "\n",
    "# Preview\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1205a2a8-82d1-408d-9947-029d3dc9e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd109498-0abd-435e-aba8-9d5a2e3ced29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count word frequencies\n",
    "counter = Counter()\n",
    "for text in train_df['text']:\n",
    "    counter.update(simple_tokenizer(text))\n",
    "\n",
    "# Build vocab dictionary (top 20k words)\n",
    "vocab_size = 20000\n",
    "vocab = {word: idx+2 for idx, (word, _) in enumerate(counter.most_common(vocab_size))}\n",
    "vocab[\"<pad>\"] = 0\n",
    "vocab[\"<unk>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44557b92-dbfb-4464-954e-b5a049a2fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, df, vocab, tokenizer, maxlen=200):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.texts[idx])\n",
    "        ids = [self.vocab.get(token, self.vocab[\"<unk>\"]) for token in tokens][:self.maxlen]\n",
    "        if len(ids) < self.maxlen:\n",
    "            ids += [self.vocab[\"<pad>\"]] * (self.maxlen - len(ids))\n",
    "        return torch.tensor(ids), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b870765-4d3f-47b0-8ea7-43142083e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = IMDBDataset(train_df, vocab, simple_tokenizer)\n",
    "valid_dataset = IMDBDataset(valid_df, vocab, simple_tokenizer)\n",
    "test_dataset  = IMDBDataset(test_df, vocab, simple_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca30fe71-0565-477f-b21a-3e43c800db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7db6c6-48b2-4c2d-b5b3-b3da287530cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6927\n",
      "Epoch 2, Loss: 0.6908\n",
      "Epoch 3, Loss: 0.5155\n",
      "Epoch 4, Loss: 0.2973\n",
      "Epoch 5, Loss: 0.2163\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SentimentLSTM(len(vocab)).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5831e110-bbc1-4f28-97bd-47ee089f10a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.44%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
    "        preds = (model(X) >= 0.5).int()\n",
    "        correct += (preds == y.int()).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a9ee03-76f8-47fc-b1ff-e8eaf7713248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save vocab dictionary to file\n",
    "with open(\"vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e225f4-b0eb-4ee9-bd41-5b470fa1a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"sentiment_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5b6bc1-309e-4db8-8c72-2a5774f01152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    tokens = simple_tokenizer(text)\n",
    "    ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens][:200]\n",
    "    if len(ids) < 200:\n",
    "        ids += [vocab[\"<pad>\"]] * (200 - len(ids))\n",
    "    X = torch.tensor([ids]).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "        return \"Positive\" if output.item() >= 0.5 else \"Negative\"\n",
    "\n",
    "print(predict_sentiment(\"This movie was amazing!\"))\n",
    "print(predict_sentiment(\"I hated every minute of it.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb13ae7-1d01-479f-a9a5-ced2d408c2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
